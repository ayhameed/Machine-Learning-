{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0d18f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 00:12:24.683949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, GRU\n",
    "from keras.optimizers import Adam\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the dataset from the Excel file\n",
    "data = pd.read_excel('../KDD_DDoS.xlsx')\n",
    "\n",
    "# Extract input features and output labels\n",
    "inputs = data.iloc[:, :41].values\n",
    "labels = data.iloc[:, 41].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.3)\n",
    "\n",
    "num_rounds = 3\n",
    "num_clients = 3\n",
    "\n",
    "client_data = np.array_split(x_train, num_clients)\n",
    "client_labels = np.array_split(y_train, num_clients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dab360f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 00:12:42.802879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'to_categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m client_data \u001b[38;5;241m=\u001b[39m convert_client_data(client_data)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Convert the client_labels array to a one-hot encoded representation\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m client_labels \u001b[38;5;241m=\u001b[39m \u001b[43mto_categorical\u001b[49m(client_labels)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Perform federated learning\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfed_learning\u001b[39m(client_data, client_labels, model_type, num_layers, num_nodes, num_output):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_categorical' is not defined"
     ]
    }
   ],
   "source": [
    "def create_model(model_type, num_input, num_layers, num_nodes, num_output):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add input layer\n",
    "    if model_type == 'RNN':\n",
    "        model.add(SimpleRNN(num_nodes, input_shape=(num_input, 1), return_sequences=False))\n",
    "    elif model_type == 'LSTM':\n",
    "        model.add(LSTM(num_nodes, input_shape=(num_input, 1), return_sequences=False))\n",
    "    \n",
    "    # Add hidden layers\n",
    "    for _ in range(num_layers):\n",
    "        model.add(Dense(num_nodes, activation='relu'))\n",
    "    \n",
    "    # Add output layer\n",
    "    model.add(Dense(num_output, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def convert_client_data(client_data):\n",
    "    '''\n",
    "        Converts the client data to a list of tensors.\n",
    "\n",
    "        Args:\n",
    "        client_data: The client data.\n",
    "\n",
    "        Returns:\n",
    "        A list of tensors, where each tensor contains the data for one time step\n",
    "        and the label for one time step.\n",
    "    '''\n",
    "    tensors = []\n",
    "    for client_data_list in client_data:\n",
    "        for i in range(len(client_data_list)):\n",
    "            tensors.append(tf.convert_to_tensor(client_data_list[i]))\n",
    "            tensors[-1] = tf.reshape(tensors[-1], (-1, 1))\n",
    "\n",
    "    return tensors\n",
    "\n",
    "\n",
    "client_data = convert_client_data(client_data)\n",
    "# Convert the client_labels array to a one-hot encoded representation\n",
    "client_labels = to_categorical(client_labels)\n",
    "\n",
    "# Perform federated learning\n",
    "def fed_learning(client_data, client_labels, model_type, num_layers, num_nodes, num_output):\n",
    "    \"\"\"Performs federated learning.\n",
    "\n",
    "    Args:\n",
    "        client_data: The client data.\n",
    "        client_labels: The client labels.\n",
    "        model_type: The type of model.\n",
    "        num_layers: The number of hidden layers.\n",
    "        num_nodes: The number of nodes in each hidden layer.\n",
    "        num_output: The number of output classes.\n",
    "\n",
    "    Returns:\n",
    "        A list of models.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert client_data and client_labels to lists\n",
    "    client_data = list(client_data)\n",
    "    client_labels = list(client_labels)\n",
    "\n",
    "    # Create local models\n",
    "    local_models = []\n",
    "    for i in range(len(client_data)):\n",
    "        num_input = len(client_data[i][0])  # Update num_input to match the shape of local_data\n",
    "        print(f\"Shape of client_data[{i}]: {client_data[i].shape}\")  # Check the shape of client_data[i]\n",
    "        local_model = create_model(model_type, num_input, num_layers, num_nodes, num_output)\n",
    "        local_data = tf.reshape(client_data[i], (client_data[i].shape[0], client_data[i].shape[1], 1))\n",
    "        local_labels = tf.reshape(client_labels[i], (client_labels[i].shape[0], 1))\n",
    "        local_model.fit(local_data, local_labels, epochs=10, batch_size=10, verbose=0)\n",
    "        local_models.append(local_model)\n",
    "\n",
    "    return local_models\n",
    "\n",
    "# Round iteration\n",
    "def round_iteration(x_test, y_test, num_rounds, num_clients, server_model):\n",
    "    \"\"\"Performs one round of federated learning.\n",
    "\n",
    "      Args:\n",
    "        x_test: The test data.\n",
    "        y_test: The test labels.\n",
    "        num_rounds: The number of rounds.\n",
    "        num_clients: The number of clients.\n",
    "        server_model: The server model.\n",
    "\n",
    "      Returns:\n",
    "        A tuple of (global accuracy, test loss, test accuracy).\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the test data\n",
    "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "    y_test = np.expand_dims(y_test, axis=-1)\n",
    "\n",
    "    #  Perform local training\n",
    "    for client in range(num_clients):\n",
    "        local_model = fed_learning(client_data[client], client_labels[client], model_type, num_layers, num_nodes, num_output)\n",
    "\n",
    "    # Update the global model with the client's weights\n",
    "    global_weights = server_model.get_weights()\n",
    "    local_weights = local_model.get_weights()\n",
    "    new_global_weights = [(global_weights[i] + local_weights[i]) / 2 for i in range(len(global_weights))]\n",
    "    server_model.set_weights(new_global_weights)\n",
    "\n",
    "    # Evaluate the global model\n",
    "    global_accuracy = server_model.evaluate(x_test, y_test, verbose=0)[1]\n",
    "    print(\"Round:\", round_, \"Global Accuracy:\", global_accuracy)\n",
    "\n",
    "    # Predict labels using the global model\n",
    "    y_pred = server_model.predict(x_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Calculate True Positive Rate (TPR)\n",
    "    tp = cm[1, 1]\n",
    "    fn = cm[1, 0]\n",
    "    tpr = tp / (tp + fn)\n",
    "\n",
    "    # Calculate False Positive Rate (FPR)\n",
    "    fp = cm[0, 1]\n",
    "    tn = cm[0, 0]\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    print(f'True Positive Rate (TPR): {tpr:.4f}')\n",
    "    print(f'False Positive Rate (FPR): {fpr:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c71de14",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RNN model architecture\n",
    "model_type = 'RNN'\n",
    "num_input = 41\n",
    "num_layers = 4\n",
    "num_nodes = 64  # Change num_nodes to an integer\n",
    "num_output = 1\n",
    "\n",
    "# Create the RNN model\n",
    "server_model = create_model(model_type, num_input, num_layers, num_nodes, num_output)\n",
    "\n",
    "# Perform federated learning\n",
    "\n",
    "fed_learning(client_data, client_labels, model_type, num_layers, num_nodes, num_output)\n",
    "\n",
    "# Round iteration\n",
    "round_iteration(x_test, y_test, num_rounds, num_clients, server_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
