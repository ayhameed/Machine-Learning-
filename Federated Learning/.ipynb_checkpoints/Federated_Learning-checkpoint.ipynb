{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20c014a3",
   "metadata": {},
   "source": [
    "# Federated Learning with Tensor Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604edb7c",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca51818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU\n",
    "from keras.optimizers import Adam\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188776a",
   "metadata": {},
   "source": [
    "# Import and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "baa6f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 20\n",
    "# Load the dataset from the Excel file\n",
    "data = pd.read_excel('../KDD_DDoS.xlsx')\n",
    "\n",
    "# Extract input features and output labels\n",
    "inputs = data.iloc[:, :41].values\n",
    "labels = data.iloc[:, 41].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3eb5d7",
   "metadata": {},
   "source": [
    "# Function to Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "923bcbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function creates only RNN Models\n",
    "def create_model(model_type, num_input, num_layers, num_nodes, num_output):\n",
    "    '''\n",
    "    Function creates models based on parameters provided, then compiles model\n",
    "    the retured model is a compiled model\n",
    "    '''\n",
    "    num_output = int(num_output)\n",
    "    if model_type == 'RNN':\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.SimpleRNN(num_nodes[0], activation='relu', return_sequences=True, input_shape=(num_input, 1)))\n",
    "        for i in range(1, num_layers - 1):\n",
    "            model.add(layers.SimpleRNN(num_nodes[i], activation='relu', return_sequences=True))\n",
    "        model.add(layers.SimpleRNN(num_nodes[-1], activation='relu'))\n",
    "        model.add(layers.Dense(num_output, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    elif model_type == 'RNN_LSTM':\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.LSTM(num_nodes[0], activation='relu', return_sequences=True, input_shape=(num_input, 1)))\n",
    "        for i in range(1, num_layers - 1):\n",
    "            model.add(layers.LSTM(num_nodes[i], activation='relu', return_sequences=True))\n",
    "        model.add(layers.LSTM(num_nodes[-1], activation='relu'))\n",
    "        model.add(layers.Dense(num_output, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    elif model_type == 'RNN_GRU':\n",
    "        model = Sequential()\n",
    "        model.add(GRU(units=num_nodes[0], activation='relu', return_sequences=True, input_shape=(num_input, 1)))\n",
    "        for i in range(1, num_layers - 1):\n",
    "            model.add(GRU(units=num_nodes[i], activation='relu', return_sequences=True))\n",
    "        model.add(GRU(units=num_nodes[-1], activation='relu'))\n",
    "        model.add(Dense(units=num_output, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model selected / Invalid parameters, try again\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182039d1",
   "metadata": {},
   "source": [
    "# Perform Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "06341c9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 956940 into shape (23340,2,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m client_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_split(y_train, num_clients)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Reshape each array within client_data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m x_train \u001b[38;5;241m=\u001b[39m \u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m x_test \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mreshape(x_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#client_data = [arr.reshape((arr.shape[0], 1, arr.shape[1])) for arr in client_data]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 956940 into shape (23340,2,1)"
     ]
    }
   ],
   "source": [
    "num_clients = 20  # Number of clients/participants\n",
    "\n",
    "# Split the training data into smaller client datasets\n",
    "client_data = np.array_split(x_train, num_clients)\n",
    "client_labels = np.array_split(y_train, num_clients)\n",
    "\n",
    "# Reshape each array within client_data\n",
    "x_train = x_train.reshape(x_train.shape[0], 2, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 2, 1)\n",
    "#client_data = [arr.reshape((arr.shape[0], 1, arr.shape[1])) for arr in client_data]\n",
    "\n",
    "def fed_learning(client_data, client_labels, server_model):    \n",
    "    local_model = tf.keras.models.clone_model(server_model)\n",
    "    local_model.set_weights(server_model.get_weights())\n",
    "    local_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Reshape each array within client_data\n",
    "    client_data = [arr[:, :, :2] for arr in client_data]\n",
    "\n",
    "    # Perform local training on each client's data\n",
    "    for i in range(len(client_data)):\n",
    "        local_data = client_data[i]\n",
    "        local_labels = client_labels[i]\n",
    "        \n",
    "        # Train the local model on the client's data\n",
    "        local_model.fit(local_data, local_labels, epochs=10, batch_size=32, verbose=0)\n",
    "    \n",
    "    return local_model\n",
    "    \n",
    "\n",
    "#round iteration\n",
    "def round_iteration(x_test, y_test, num_rounds, num_clients, server_model):\n",
    "    # Round iteration\n",
    "    for round_ in range(num_rounds):       \n",
    "        # Iterate over each client and perform local training\n",
    "        for client in range(num_clients):\n",
    "            local_model = fed_learning(client_data[client], client_labels[client], server_model)\n",
    "            \n",
    "            # Update the global model with the client's weights\n",
    "            global_weights = server_model.get_weights()\n",
    "            local_weights = local_model.get_weights()\n",
    "            averaged_weights = [(global_weights[i] + local_weights[i]) / 2 for i in range(len(global_weights))]\n",
    "            server_model.set_weights(averaged_weights)\n",
    "            \n",
    "            #reshape x_test\n",
    "            x_test2=np.array(x_test)\n",
    "            x_test2=x_test2.reshape(x_test2.shape[0],1,x_test2.shape[1])\n",
    "\n",
    "            loss, accuracy = server_model.evaluate(x_test2, y_test)\n",
    "            print(\"\\n*********** Round-\",round_,\":Client\",client,\" ***********\\n\")\n",
    "            print(f'Test loss: {loss:.4f}')\n",
    "            print(f'Test accuracy: {accuracy:.4f}')\n",
    "\n",
    "    # Evaluate the global model on the testing data\n",
    "    print(\"\\n=========== Round-\",round_,\":Client\",client,\" ===========\\n\")\n",
    "    loss, accuracy = model.evaluate(x_test, x_test)\n",
    "    print(f'Test loss: {loss:.4f}')\n",
    "    print(f'Test accuracy: {accuracy:.4f}')\n",
    "    return x_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724af044",
   "metadata": {},
   "source": [
    "# Function to Calculate metrics and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a12069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(x_test2, y_test):\n",
    "    y_pred = server_model.predict(x_test2)\n",
    "    ypred = (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    #calculate metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    tpr = tp / (tp + fn)\n",
    "    \n",
    "    if (tn + fp) != 0:\n",
    "        fpr = fp / (tn + fp)\n",
    "    else:\n",
    "        fpr = 0.0\n",
    "    print(f'{accuracy}')\n",
    "    print(f'{tpr}')\n",
    "    print(f'{fpr}')\n",
    "    return accuracy, tpr, fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b69f95",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify Model parameters\n",
    "model_type = 'RNN'\n",
    "num_input = 2\n",
    "num_layers = 5\n",
    "num_nodes = [64] * num_layers\n",
    "num_output = 1\n",
    "\n",
    "#Create and Compile Model\n",
    "server_model= create_model(x_test, y_test,model_type, num_input, num_layers, num_nodes, num_output)\n",
    "\n",
    "#implement fed_learning\n",
    "fed_learning(client_data, client_labels, server_model)\n",
    "\n",
    "#round iteration\n",
    "round_iteration(num_rounds, num_clients, server_model)\n",
    "\n",
    "#metrics and predictions\n",
    "get_metrics(x_test2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ef43a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
