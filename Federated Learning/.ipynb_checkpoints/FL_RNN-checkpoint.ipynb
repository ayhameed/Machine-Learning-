{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e180dfe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, GRU\n",
    "from keras.optimizers import Adam\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "num_rounds = 2\n",
    "# Load the dataset from the Excel file\n",
    "data = pd.read_excel('../KDD_DDoS.xlsx')\n",
    "\n",
    "# Extract input features and output labels\n",
    "inputs = data.iloc[:, :41].values\n",
    "labels = data.iloc[:, 41:42].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba3669c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_type, num_input, num_layers, num_nodes, num_output):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Add input layer\n",
    "    if model_type == 'RNN':\n",
    "        model.add(keras.layers.SimpleRNN(num_nodes, input_shape=(1,num_input), return_sequences=True))\n",
    "    elif model_type == 'LSTM':\n",
    "        model.add(keras.layers.LSTM(num_nodes, input_shape=(1, num_input), return_sequences=True))\n",
    "\n",
    "    # Add hidden layers\n",
    "    for _ in range(num_layers):\n",
    "        model.add(keras.layers.Dense(num_nodes, activation='relu'))\n",
    "\n",
    "    # Add output layer\n",
    "    model.add(keras.layers.Dense(num_output, activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Perform federated learning\n",
    "num_clients = 20# Number of clients/participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d2013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into smaller client datasets\n",
    "client_data = np.array_split(X_train, num_clients)  # client_data[0] ... client_data[9]\n",
    "client_labels = np.array_split(y_train, num_clients)\n",
    "\n",
    "def fed_learning(client_data, client_labels, server_model):\n",
    "    local_model = tf.keras.models.clone_model(server_model)\n",
    "    local_model.set_weights(server_model.get_weights())\n",
    "    local_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # change the dimension here!!!\n",
    "    client_data2 = np.array(client_data)\n",
    "    client_data2 = client_data2.reshape(client_data2.shape[0], 1, client_data2.shape[1])\n",
    "    \n",
    "    client_labels = np.array(client_labels)\n",
    "    client_labels = client_labels.reshape(client_labels.shape[0], 1)  # Reshape client_labels\n",
    "    \n",
    "    # Perform local training on the client's data\n",
    "    local_model.fit(client_data2, client_labels, epochs=10, batch_size=32, verbose=0)\n",
    "    return local_model\n",
    "\n",
    "# Round iteration\n",
    "def round_iter(num_rounds):\n",
    "    \n",
    "    #list to hold value for each round \n",
    "    accuracy_list = []\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    \n",
    "    for round_ in range(num_rounds):       \n",
    "        # Iterate over each client and perform local training\n",
    "        for client in range(num_clients):\n",
    "            local_model = fed_learning(client_data[client], client_labels[client], model) \n",
    "            # Update the global model with the client's weights\n",
    "            global_weights = model.get_weights()\n",
    "            local_weights = local_model.get_weights()\n",
    "            averaged_weights = [(global_weights[i] + local_weights[i]) / 2 for i in range(len(global_weights))]\n",
    "            model.set_weights(averaged_weights)\n",
    "\n",
    "            X_test2 = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "            loss, accuracy = model.evaluate(X_test2, y_test)\n",
    "            print(\"\\n*********** Round-\", round_, \":Client\", client, \" ***********\\n\")\n",
    "            print(f'Test loss: {loss:.4f}')\n",
    "            print(f'Test accuracy: {accuracy:.4f}')\n",
    "            \n",
    "            # Calculate TPR and FPR\n",
    "            y_pred = model.predict(X_test2)\n",
    "            y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "            tp = np.sum((y_test == 1) & (y_pred_binary == 1))\n",
    "            fp = np.sum((y_test == 0) & (y_pred_binary == 1))\n",
    "            tn = np.sum((y_test == 0) & (y_pred_binary == 0))\n",
    "            fn = np.sum((y_test == 1) & (y_pred_binary == 0))\n",
    "            tpr = tp / (tp + fn)\n",
    "            fpr = fp / (fp + tn)\n",
    "\n",
    "            # Append values to lists\n",
    "            accuracy_list.append(accuracy)\n",
    "            tpr_list.append(tpr)\n",
    "            fpr_list.append(fpr)\n",
    "\n",
    "    # Evaluate the global model on the testing data\n",
    "    print(\"\\n=========== Round-\", round_, \":Client\", client, \" ===========\\n\")\n",
    "    X_test2 = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "    loss, accuracy = model.evaluate(X_test2, y_test)\n",
    "    print(f'Test loss: {loss:.4f}')\n",
    "    print(f'Test accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return accuracy_list, tpr_list, fpr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f717538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 01:38:43.348821: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 1s 1ms/step - loss: 0.2174 - accuracy: 0.9448\n",
      "\n",
      "*********** Round- 0 :Client 0  ***********\n",
      "\n",
      "Test loss: 0.2174\n",
      "Test accuracy: 0.9448\n",
      "183/183 [==============================] - 0s 911us/step\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9476\n",
      "\n",
      "*********** Round- 0 :Client 1  ***********\n",
      "\n",
      "Test loss: 0.1458\n",
      "Test accuracy: 0.9476\n",
      "183/183 [==============================] - 0s 884us/step\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9542\n",
      "\n",
      "*********** Round- 0 :Client 2  ***********\n",
      "\n",
      "Test loss: 0.1189\n",
      "Test accuracy: 0.9542\n",
      "183/183 [==============================] - 0s 915us/step\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.9549\n",
      "\n",
      "*********** Round- 0 :Client 3  ***********\n",
      "\n",
      "Test loss: 0.1175\n",
      "Test accuracy: 0.9549\n",
      "183/183 [==============================] - 0s 834us/step\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.9254\n",
      "\n",
      "*********** Round- 0 :Client 4  ***********\n",
      "\n",
      "Test loss: 0.1332\n",
      "Test accuracy: 0.9254\n",
      "183/183 [==============================] - 0s 871us/step\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9553\n",
      "\n",
      "*********** Round- 0 :Client 5  ***********\n",
      "\n",
      "Test loss: 0.1058\n",
      "Test accuracy: 0.9553\n",
      "183/183 [==============================] - 0s 842us/step\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.1037 - accuracy: 0.9582\n",
      "\n",
      "*********** Round- 0 :Client 6  ***********\n",
      "\n",
      "Test loss: 0.1037\n",
      "Test accuracy: 0.9582\n",
      "183/183 [==============================] - 0s 816us/step\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.9704\n",
      "\n",
      "*********** Round- 0 :Client 7  ***********\n",
      "\n",
      "Test loss: 0.0858\n",
      "Test accuracy: 0.9704\n",
      "183/183 [==============================] - 0s 821us/step\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.1107 - accuracy: 0.9472\n",
      "\n",
      "*********** Round- 0 :Client 8  ***********\n",
      "\n",
      "Test loss: 0.1107\n",
      "Test accuracy: 0.9472\n",
      "183/183 [==============================] - 0s 851us/step\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9506\n",
      "\n",
      "*********** Round- 0 :Client 9  ***********\n",
      "\n",
      "Test loss: 0.1039\n",
      "Test accuracy: 0.9506\n",
      "183/183 [==============================] - 0s 869us/step\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.0975 - accuracy: 0.9563\n",
      "\n",
      "*********** Round- 0 :Client 10  ***********\n",
      "\n",
      "Test loss: 0.0975\n",
      "Test accuracy: 0.9563\n",
      "183/183 [==============================] - 0s 857us/step\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9604\n",
      "\n",
      "*********** Round- 0 :Client 11  ***********\n",
      "\n",
      "Test loss: 0.0994\n",
      "Test accuracy: 0.9604\n",
      "183/183 [==============================] - 0s 872us/step\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9650\n",
      "\n",
      "*********** Round- 0 :Client 12  ***********\n",
      "\n",
      "Test loss: 0.0899\n",
      "Test accuracy: 0.9650\n",
      "183/183 [==============================] - 0s 841us/step\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9661\n",
      "\n",
      "*********** Round- 0 :Client 13  ***********\n",
      "\n",
      "Test loss: 0.0869\n",
      "Test accuracy: 0.9661\n",
      "183/183 [==============================] - 0s 816us/step\n"
     ]
    }
   ],
   "source": [
    "#RNN\n",
    "# Create Model\n",
    "model = create_model('RNN', 41, 4, 64, 1)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#round iteration & fed learning get metrics\n",
    "\n",
    "rnn_acc, rnn_tpr, rnn_fpr = round_iter(num_rounds)\n",
    "\n",
    "print(f'rnn accuracy list {rnn_acc}')\n",
    "print(f'rnn accuracy list {rnn_tpr}')\n",
    "print(f'rnn accuracy list {rnn_fpr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f40bc6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LSTM\n",
    "# Create Model\n",
    "model = create_model('LSTM', 41, 4, 64, 1)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#round iteration & fed learning\n",
    "lstm_acc, lstm_tpr, lstm_fpr = round_iter(num_rounds)\n",
    "\n",
    "print(f'lstm accuracy list {lstm_acc}')\n",
    "print(f'lstm accuracy list {lstm_tpr}')\n",
    "print(f'lstm accuracy list {lstm_fpr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d8e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test lenght \n",
    "lenof_rnn_acc = len(rnn_acc)\n",
    "lenof_lstm_acc = len(lstm_acc)\n",
    "\n",
    "print(f'rnn {lenof_rnn_acc}')\n",
    "print(f'lstm {lenof_lstm_acc }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edad8a1",
   "metadata": {},
   "source": [
    "# plot graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e6c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d6592d",
   "metadata": {},
   "source": [
    "# Accuracy vs rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc828ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the lengths of lstm_acc and rnn_acc are the same\n",
    "num_rounds = len(lstm_acc)\n",
    "\n",
    "# Aligning the lengths of lstm_acc and rnn_acc to the specified number of rounds\n",
    "lstm_acc = lstm_acc[:num_rounds]\n",
    "rnn_acc = rnn_acc[:num_rounds]\n",
    "\n",
    "# Set the x-axis values\n",
    "x = np.arange(1, num_rounds + 1)\n",
    "\n",
    "# Plot the line for LSTM Model accuracy\n",
    "plt.plot(x, lstm_acc, marker='o', linestyle='-', color='blue', label='LSTM Model')\n",
    "\n",
    "# Plot the line for RNN Model accuracy\n",
    "plt.plot(x, rnn_acc, marker='s', linestyle='--', color='orange', label='RNN Model')\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Rounds')\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Set the title of the graph\n",
    "plt.title('Accuracy Comparison: LSTM Model vs RNN Model')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994138a0",
   "metadata": {},
   "source": [
    "# TPR vs Rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637dbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aligning the lengths of lstm_tpr and rnn_tpr to the specified number of rounds\n",
    "lstm_tpr = lstm_tpr[:num_rounds]\n",
    "rnn_tpr = rnn_tpr[:num_rounds]\n",
    "\n",
    "# Set the x-axis values\n",
    "x = np.arange(1, num_rounds + 1)\n",
    "\n",
    "# Plot the line for LSTM Model tpr\n",
    "plt.plot(x, lstm_tpr, marker='o', linestyle='-', color='blue', label='LSTM Model')\n",
    "\n",
    "# Plot the line for RNN Model tpr\n",
    "plt.plot(x, rnn_tpr, marker='s', linestyle='--', color='orange', label='RNN Model')\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Rounds')\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel('tpr')\n",
    "\n",
    "# Set the title of the graph\n",
    "plt.title('TPR Comparison: LSTM Model vs RNN Model')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ba01c8",
   "metadata": {},
   "source": [
    "# FPR vs Rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b71941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aligning the lengths of lstm_fpr and rnn_fpr to the specified number of rounds\n",
    "lstm_fpr = lstm_fpr[:num_rounds]\n",
    "rnn_fpr = rnn_fpr[:num_rounds]\n",
    "\n",
    "# Set the x-axis values\n",
    "x = np.arange(1, num_rounds + 1)\n",
    "\n",
    "# Plot the line for LSTM Model fpr\n",
    "plt.plot(x, lstm_fpr, marker='o', linestyle='-', color='blue', label='LSTM Model')\n",
    "\n",
    "# Plot the line for RNN Model fpr\n",
    "plt.plot(x, rnn_fpr, marker='s', linestyle='--', color='orange', label='RNN Model')\n",
    "\n",
    "# Set the x-axis label\n",
    "plt.xlabel('Rounds')\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel('fpr')\n",
    "\n",
    "# Set the title of the graph\n",
    "plt.title('FPR Comparison: LSTM Model vs RNN Model')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Add grid lines\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f773ad",
   "metadata": {},
   "source": [
    "# Print Data Frame for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff78f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the lengths of fpr, tpr, and accuracy are the same\n",
    "data = {\n",
    "    'Rounds': range(1, len(rnn_fpr) + 1),\n",
    "    'RNN Accuracy': rnn_acc,\n",
    "    'RNN FPR': rnn_fpr,\n",
    "    'RNN TPR': rnn_tpr,\n",
    "    'LSTM Accuracy': lstm_acc,\n",
    "    'LSTM FPR': lstm_fpr,\n",
    "    'LSTM TPR': lstm_tpr\n",
    "    \n",
    "}\n",
    "# Set the maximum number of columns to display\n",
    "pd.set_option('display.max_columns', None)  # Show all column\n",
    "# Set the maximum number of rows to display\n",
    "pd.set_option('display.max_rows', 10)  # Show all rows# Show all rows\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
