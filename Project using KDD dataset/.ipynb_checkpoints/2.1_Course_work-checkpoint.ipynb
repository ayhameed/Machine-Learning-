{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b1b8ae2-b482-4992-9292-eed86d59be3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imported Libraries <a class=\"anchor\" id=\"libraries\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfec1667-7518-461f-91fc-38ecb3ac4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d57ae16-802c-4e21-879e-97ef310debcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Function Definations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1a7d2-4b56-44cd-820f-2e392d2df86f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function to display the numbers of rows and colums and non numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef4c83f1-a92c-4f16-8545-02b0ad47fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataset_info(loaded_data_set):\n",
    "    \"\"\"\n",
    "    Displays the dataset information, the numbers of rows and columns, and the sum of the number of rows\n",
    "    with non-numeric data across all columns.\n",
    "\n",
    "    Usage:\n",
    "        display_dataset_info(loaded_data_set)\n",
    "\n",
    "    Args:\n",
    "        loaded_data_set (str): The loaded variable containing the path to the dataset\n",
    "\n",
    "    Outputs:\n",
    "        row: The number of rows.\n",
    "        columns: The number of columns.\n",
    "        non-numerical data: The sum of the number of rows with non-numeric data across all columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Display the number of rows and columns\n",
    "    num_rows = len(loaded_data_set)\n",
    "    num_cols = len(loaded_data_set.columns)\n",
    "    print(\"Number of rows:\", num_rows)\n",
    "    print(\"Number of columns:\", num_cols)\n",
    "\n",
    "    # Find rows with non-numeric values\n",
    "    non_numeric_rows = loaded_data_set.apply(lambda x: pd.to_numeric(x, errors='coerce').isna().any(), axis=1)\n",
    "\n",
    "    # Calculate the sum of the number of rows with non-numeric data across all columns\n",
    "    non_numeric_count = non_numeric_rows.sum()\n",
    "\n",
    "    # Display the sum of the number of rows with non-numeric data\n",
    "    print(\"Non-numeric data:\", non_numeric_count, \"rows\")\n",
    "\n",
    "    # Return the count of non-numeric rows\n",
    "    return non_numeric_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf3c7b1-414c-4dab-8ada-9f51e3876035",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function to merge datasets into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95ddab8d-d92e-4539-9953-9a189fefc0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(*datasets):\n",
    "    \"\"\"\n",
    "    Merges datasets into one\n",
    "    \n",
    "    Usage:\n",
    "        merged_data = merge_datasets(*datasets)\n",
    "    \n",
    "    Args:\n",
    "        *datasets(str): at least 2 data sets \n",
    "        \n",
    "    return:\n",
    "        merged_data: the merged data ser \n",
    "    \"\"\"\n",
    "    merged_data = pd.concat(datasets)\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9e5760-e49c-4859-b021-24bdcf4eb689",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function to Cleanse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53bf3cf5-b6bf-4ef1-9290-65637212f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleansing(data):\n",
    "    \"\"\"\n",
    "    Performs data cleansing operations on the input dataset.\n",
    "\n",
    "    Tasks performed:\n",
    "    a) Removes rows with NULL/empty cells.\n",
    "    b) Removes rows with non-numeric values.\n",
    "    c) Displays the number of columns and rows after data cleansing.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): The input dataset.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The cleansed dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove rows with NULL/empty cells\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Remove rows with non-numeric values\n",
    "    data = data.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "    # Display the number of columns and rows after data cleansing\n",
    "    num_rows = len(data)\n",
    "    num_cols = len(data.columns)\n",
    "    print(\"Number of rows:\", num_rows)\n",
    "    print(\"Number of columns:\", num_cols)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90458691-044e-42ae-ae4b-d1df49232a6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function to perform feature reduction and check for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e3f247a-109d-48f1-ab09-abf4f69c6f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_dimensionality_reduction(data):\n",
    "    \"\"\"\n",
    "    Perform dimensionality reduction based on correlation and display the number of features/columns\n",
    "    and records after the reduction.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): The input dataset for dimensionality reduction.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The reduced dataset after dimensionality reduction.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = data.corr().abs()\n",
    "\n",
    "    # Find features with correlation greater than 0.99\n",
    "    highly_correlated_features = set()\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if correlation_matrix.iloc[i, j] > 0.99:\n",
    "                feature_name = correlation_matrix.columns[i]\n",
    "                highly_correlated_features.add(feature_name)\n",
    "\n",
    "    # Perform dimensionality reduction\n",
    "    reduced_data = data.drop(columns=highly_correlated_features)\n",
    "\n",
    "    # Display number of features/columns and records after reduction\n",
    "    num_features_before = data.shape[1]\n",
    "    num_features_after = reduced_data.shape[1]\n",
    "    num_records = reduced_data.shape[0]\n",
    "    print(\"Number of correlated features at 0.99 threshold:\", len(highly_correlated_features))\n",
    "    print(\"Number of features/columns before reduction:\", num_features_before)\n",
    "    print(\"Number of features/columns after reduction:\", num_features_after)\n",
    "    print(\"Number of records after reduction:\", num_records)\n",
    "\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a9cec-eee1-40b6-9a5b-48f7411f7960",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function to segment data and return a tuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2502ec74-447b-4f6a-a2a4-1d4fb73466e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data, tst_size):\n",
    "    \"\"\"\n",
    "    Split the dataset into training and testing sets using speciifed test size and return X_train, X_test, y_train, y_test.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): The loaded dataset.\n",
    "        tst_size: The test size\n",
    "    Returns:\n",
    "        tuple: A tuple containing X_train, X_test, y_train, and y_test.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the data into features (X) and target variable (y)\n",
    "    X = data.iloc[:, :40]  \n",
    "    y = data.iloc[:, 40:41]\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tst_size, random_state=42)\n",
    "\n",
    "    # Display the shape of the resulting datasets\n",
    "    print(\"Shape of X_train:\", X_train.shape)\n",
    "    print(\"Shape of X_test:\", X_test.shape)\n",
    "    print(\"Shape of y_train:\", y_train.shape)\n",
    "    print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e788de9-ab7f-4484-b471-5222358a15fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2.1 Dataset loading and pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2effb8b3-36fd-4510-bc32-a805efa41692",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading the data in different vectors and display data set information <a class=\"anchor\" id=\"load_data\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6ff1462-1e5e-42c5-afad-33d22cd57a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 29132\n",
      "Number of columns: 42\n",
      "Non-numeric data: 1470 rows\n"
     ]
    }
   ],
   "source": [
    "# Read data KDD_DDoS\n",
    "kdd_ddos_data = pd.read_excel(\"KDD_DDoS.xlsx\")\n",
    "\n",
    "#Display number of rows, columns and non-numeric data\n",
    "kdd_ddos_data_det = display_dataset_info(kdd_ddos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4cb7e4f-9e60-41e1-ae16-e17725756ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 20292\n",
      "Number of columns: 42\n",
      "Non-numeric data: 1373 rows\n"
     ]
    }
   ],
   "source": [
    "# Read data KDD_Probe\n",
    "kdd_probe_data = pd.read_excel(\"KDD_Probe.xlsx\")\n",
    "\n",
    "#Display number of rows, columns and non-numeric data\n",
    "kdd_probe_data_det = display_dataset_info(kdd_probe_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "406d1199-0c73-4d29-9414-8c5f4a969b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 18564\n",
      "Number of columns: 42\n",
      "Non-numeric data: 535 rows\n"
     ]
    }
   ],
   "source": [
    "# Read data KDD_R2L\n",
    "kdd_r2l_data = pd.read_excel(\"KDD_R2L.xlsx\")\n",
    "\n",
    "#Display number of rows, columns and non-numeric data\n",
    "kdd_r2l_data_det = display_dataset_info(kdd_r2l_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3ca8173-84b6-43b7-ab9a-94b64767c350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 15734\n",
      "Number of columns: 42\n",
      "Non-numeric data: 1022 rows\n"
     ]
    }
   ],
   "source": [
    "# Read data KDD_U2R\n",
    "kdd_u2r_data = pd.read_excel(\"KDD_U2R.xlsx\")\n",
    "\n",
    "#Display number of rows, columns and non-numeric data\n",
    "kdd_u2r_data_det = display_dataset_info(kdd_u2r_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8c5c8be-c1ad-4243-8c59-3e01d0a5b32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 225745\n",
      "Number of columns: 79\n",
      "Non-numeric data: 2112 rows\n"
     ]
    }
   ],
   "source": [
    "# Read data CICIDS_DoS\n",
    "CICIDS_DoS_data = pd.read_excel(\"CICIDS_DoS.xlsx\")\n",
    "\n",
    "#Display number of rows, columns and non-numeric data\n",
    "CICIDS_DoS_data_det = display_dataset_info(CICIDS_DoS_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3379daef-2a2c-4e0d-9ef0-2d9d62d4cab9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Perform data cleansing in each data frame/vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30408185-affd-43c4-bc2a-560ff3d92d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 27662\n",
      "Number of columns: 42\n"
     ]
    }
   ],
   "source": [
    "#Cleansing for KDD DDOS\n",
    "kdd_ddos_data = data_cleansing(kdd_ddos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0759f5b-2c57-4468-a086-abd3f353faed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 18919\n",
      "Number of columns: 42\n"
     ]
    }
   ],
   "source": [
    "#Cleansing for KDD_Probe\n",
    "kdd_probe_data = data_cleansing(kdd_probe_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95005509-ee10-46ed-a54d-09ca4b40a2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 18029\n",
      "Number of columns: 42\n"
     ]
    }
   ],
   "source": [
    "#Cleansing for KDD_R2l Data\n",
    "kdd_r2l_data = data_cleansing(kdd_r2l_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d0a1dd2-4249-44ca-b6a3-24bcf8f03f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 14712\n",
      "Number of columns: 42\n"
     ]
    }
   ],
   "source": [
    "#Cleansing for KDD_u2r_data\n",
    "kdd_u2r_data = data_cleansing(kdd_u2r_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "410c0a2c-aa6e-4877-981d-5724be6db436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 223633\n",
      "Number of columns: 79\n"
     ]
    }
   ],
   "source": [
    "#Cleansing for CICIDS_DoS\n",
    "CICIDS_DoS_data = data_cleansing(CICIDS_DoS_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff506004-f32c-4447-a64a-7b8533e5e344",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Combine/Merging all the data frames/vectors from NSL-KDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba56e5dc-d33d-4d1f-93ab-65256b6cb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_NSL_Final = merge_datasets(kdd_ddos_data, kdd_probe_data, kdd_r2l_data, kdd_u2r_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde41c8a-9102-47f6-a103-960c5171a88b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dimensionality/Features reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb80b84-f67f-452a-b9a9-2b1092fb3159",
   "metadata": {},
   "source": [
    "### Combine, then Display the features before feature redsuction from the combined NSL-KDD dataset and CICIDS(uncombined) before Feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51c26104-72de-4210-ba6a-a48176a75fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 79322\n",
      "Number of columns: 42\n",
      "Non-numeric data: 0 rows\n"
     ]
    }
   ],
   "source": [
    "# Display the features before feature reduction from the combined NSL-KDD dataset\n",
    "DS_NSL_Final_info = display_dataset_info(DS_NSL_Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c00bd81d-0bf4-484e-81d2-d7243681286d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 223633\n",
      "Number of columns: 79\n",
      "Non-numeric data: 0 rows\n"
     ]
    }
   ],
   "source": [
    "# Display the features before feature reduction from the combined CICIDS dataset\n",
    "CICIDS_DoS_data_info = display_dataset_info(CICIDS_DoS_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27308e58-93b6-4558-bcca-429d47abcef9",
   "metadata": {},
   "source": [
    "### Display the features before feature redsuction from the combined NSL-KDD dataset and CICIDS(uncombined) after Feature reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33596dfa-49d8-409f-b025-f15cfb11bc73",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature Extraction on Combined NSL-KDD along with the details of the features afterwards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abc0bfaf-926e-424f-b7e6-cf9ba0275c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correlated features at 0.99 threshold: 1\n",
      "Number of features/columns before reduction: 42\n",
      "Number of features/columns after reduction: 41\n",
      "Number of records after reduction: 79322\n"
     ]
    }
   ],
   "source": [
    "# Feature reduction on combined NSL-KDD data set\n",
    "DS_NSL_Final = perform_dimensionality_reduction(DS_NSL_Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d14fae05-7d11-4b94-9e01-b48ff4310518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correlated features at 0.99 threshold: 15\n",
      "Number of features/columns before reduction: 79\n",
      "Number of features/columns after reduction: 64\n",
      "Number of records after reduction: 223633\n"
     ]
    }
   ],
   "source": [
    "# Feature reduction on combined CICDS data set\n",
    "CICIDS_DoS_data = perform_dimensionality_reduction(CICIDS_DoS_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a8c235-d8ef-43e7-bcfd-924d4ccc36d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Display number of features/columns and number of records in both vectors i.e NSL-KDD combined and CICDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1db848a1-4a47-4e4c-bb68-cbd2e037cd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 79322\n",
      "Number of columns: 41\n",
      "Non-numeric data: 0 rows\n"
     ]
    }
   ],
   "source": [
    "# Display the features after feature reduction from the combined NSL-KDD dataset\n",
    "DS_NSL_Final_info_final = display_dataset_info(DS_NSL_Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98b85fb6-686d-40c5-b7ed-573291dadb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 223633\n",
      "Number of columns: 64\n",
      "Non-numeric data: 0 rows\n"
     ]
    }
   ],
   "source": [
    "# Display the features after feature reduction from the combined CICIDS dataset\n",
    "CICIDS_DoS_data_info_final = display_dataset_info(CICIDS_DoS_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039bdfe4-bf04-463f-a2a2-e0cfa1793938",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data segmentation: Segmenting Comnbined NSL-KDD and CICDS and displa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2b4e2c-1405-4f90-92a6-d7bf1aed99e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Segmenting Combined NSL-KDD into 30% testing and 70% training, then display the numbers of columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d013fbe-85a0-433a-9ab8-f0ffe451b32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (55525, 40)\n",
      "Shape of X_test: (23797, 40)\n",
      "Shape of y_train: (55525, 1)\n",
      "Shape of y_test: (23797, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_KDD, X_test_KDD, y_train_KDD, y_test_KDD = split_dataset(DS_NSL_Final, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6738fe28-e43f-47f8-81b1-7c30581b81b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Segmenting Combined CICDS into 30% testing and 70% training, then display the numbers of columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8cb1bea5-52ca-4379-b75e-26d6e0193c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (156543, 40)\n",
      "Shape of X_test: (67090, 40)\n",
      "Shape of y_train: (156543, 1)\n",
      "Shape of y_test: (67090, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_KDD, X_test_KDD, y_train_KDD, y_test_KDD = split_dataset(CICIDS_DoS_data, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08260236-687a-426b-a3cd-cd6ff501926c",
   "metadata": {},
   "source": [
    "## write the Preprocessed and  combined NSL_KDD dataset to an excel sheet for reuse in subsequent tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b6c6545-d73a-4b7f-b785-a8c848be0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output file path\n",
    "output_file_path = 'DS_NSL_Final.xlsx'\n",
    "\n",
    "# Write the combined dataset to an Excel file\n",
    "DS_NSL_Final.to_excel(output_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
