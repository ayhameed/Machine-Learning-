{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9572835-5a4a-4bec-bb1b-21eec0d64553",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6aa199fe-8c0b-4d23-ad17-d5f4013fd5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import time\n",
    "import ray\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8584673b-d9ec-4518-b49f-401b4ae8cffc",
   "metadata": {},
   "source": [
    "# Define functions to create SL and DL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "491391e6-856b-4aab-94f9-6427fd5d3893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create Shallow Learning Model (KNN)\n",
    "def create_shallow_model():\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    return model\n",
    "\n",
    "# Define a function to create Deep Learning Model (DNN)\n",
    "def create_deep_model(num_input, num_output):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(num_input,)))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(num_output, activation='sigmoid'))  # Use softmax activation for multi-class classification\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b82722-7ad5-4f90-862d-34054ee2e1a7",
   "metadata": {},
   "source": [
    "# Define Parallel Functions to train SL and DL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b50fba-4b69-45ba-a037-3652220c0a71",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function to Train Shallow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a6e456b-cae2-42c5-b4e6-557ec7670c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def train_shallow_model(X_train, y_train, X_test, y_test):\n",
    "    # Create and train the Shallow Learning Model (KNN)\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    accuracies = []\n",
    "\n",
    "    for _ in range(20):\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return accuracies[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6968f2-8556-40d8-a6f6-76ee28321fdf",
   "metadata": {},
   "source": [
    "## Function to Train Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "62a1c590-4331-43e6-a3bc-e2c9a579516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def train_deep_model(X_train, y_train, X_test, y_test):\n",
    "    # Create and train the Deep Learning Model (DNN)\n",
    "    model = create_deep_model(X_train.shape[1], len(np.unique(y_train)))\n",
    "\n",
    "    for _ in range(20):\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=0)\n",
    "\n",
    "    # Evaluate the model on the test data and return the accuracy and weights\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    weights = model.get_weights()\n",
    "    return accuracy, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b6304-9122-42d3-b710-c758c8b048f5",
   "metadata": {},
   "source": [
    "# Functions to perform Federated Learning on DL and SL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae0e874-da66-44f5-b972-f4135470ad05",
   "metadata": {},
   "source": [
    "## Peform FL on KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ec61d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fl_knn():\n",
    "    # Generate some random numerical data\n",
    "    dataset = pd.read_excel(\"DS_NSL_Final.xlsx\")\n",
    "    ipt_data = dataset.iloc[:, :-2]\n",
    "    opt_data = dataset.iloc[:, -2:-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(ipt_data, opt_data, test_size=0.3, random_state=1985)\n",
    "\n",
    "    # Reshape y_train and y_test into 1D arrays\n",
    "    y_train = np.ravel(y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "\n",
    "    # Initialize Ray\n",
    "    ray.shutdown()\n",
    "    ray.init()\n",
    "\n",
    "    num_clients = 10\n",
    "    x_batches = np.array_split(x_train, num_clients)\n",
    "    y_batches = np.array_split(y_train, num_clients)\n",
    "    model = create_shallow_model()\n",
    "\n",
    "    for round_ in range(4):\n",
    "        # Train the model in parallel\n",
    "        startTime = time.time()\n",
    "        results = [train_shallow_model.remote(x_batches[i], y_batches[i], x_test, y_test) for i in range(num_clients)]\n",
    "        accuracies = ray.get(results)\n",
    "        print(\"Round:\", round_+1, \" Average Accuracy:\", np.mean(accuracies), \" Total time: \", time.time() - startTime, \"seconds\")\n",
    "        \n",
    "    # Fit the model with all the training data\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    accuracy = model.score(x_test, y_test)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    print(\"*********************** The value of Accuracy = \", accuracy, \"  ********************************\")\n",
    "    ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b4adef-bb64-4a1a-8485-da8a1b81d26a",
   "metadata": {},
   "source": [
    "### Execute FL on SL (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d13d8b2-85fe-4cec-a6db-f6abad07d561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 17:13:33,748\tINFO worker.py:1625 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1  Average Accuracy: 0.9158549396982811  Total time:  84.37151384353638 seconds\n",
      "Round: 2  Average Accuracy: 0.9158549396982811  Total time:  80.81651782989502 seconds\n",
      "Round: 3  Average Accuracy: 0.9158549396982811  Total time:  81.24969291687012 seconds\n",
      "Round: 4  Average Accuracy: 0.9158549396982811  Total time:  81.79906272888184 seconds\n",
      "Test Accuracy: 0.9548262386015044\n",
      "*********************** The value of Accuracy =  0.9548262386015044   ********************************\n"
     ]
    }
   ],
   "source": [
    "fl_knn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb288e04-25c1-40fa-86e6-0f7168143c67",
   "metadata": {},
   "source": [
    "## Perform FL on DL (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "62a0ed4b-faf7-4d2e-baac-15a168def0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fl_dnn():\n",
    "    # Generate some random numerical data\n",
    "    dataset = pd.read_excel(\"DS_NSL_Final.xlsx\")\n",
    "    ipt_data = dataset.iloc[:, :40]\n",
    "    opt_data = dataset.iloc[:, 40:41]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(ipt_data, opt_data, test_size=0.3, random_state=95)\n",
    "\n",
    "    # Reshape y_train and y_test into 1D arrays\n",
    "    y_train = np.ravel(y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "\n",
    "    # Initialize Ray\n",
    "    ray.shutdown()\n",
    "    ray.init()\n",
    "\n",
    "    num_clients = 10\n",
    "    x_batches = np.array_split(x_train, num_clients)\n",
    "    y_batches = np.array_split(y_train, num_clients)\n",
    "    model = create_deep_model(x_train.shape[1], len(np.unique(y_train)))\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    for round_ in range(4):\n",
    "        # Train the model in parallel\n",
    "        startTime = time.time()\n",
    "        results = [train_deep_model.remote(x_batches[i], y_batches[i], x_test, y_test) for i in range(num_clients)]\n",
    "        accuracies, weights = zip(*ray.get(results))\n",
    "        print(\"Round:\", round_+1, \" Average Accuracy:\", np.mean(accuracies), \" Total time:\", time.time() - startTime, \"seconds\")\n",
    "\n",
    "        # Combine the weights from each batch and update the model\n",
    "        combined_weights = [np.mean(w, axis=1) for w in zip(*weights)]\n",
    "        # Adjust the weights of the global model using federated weights\n",
    "        global_weights = model.get_weights()\n",
    "\n",
    "        # Combine the weights from each batch and update the model\n",
    "        combined_weights = [np.mean(w, axis=0) for w in zip(*global_weights)]\n",
    "        adjusted_weights = []\n",
    "        for i, layer_weights in enumerate(combined_weights):\n",
    "            expected_shape = model.layers[i].get_weights()[0].shape\n",
    "            if layer_weights.shape != expected_shape:\n",
    "                # Reshape the layer weights to match the expected shape\n",
    "                if len(layer_weights.shape) == 2:  # Fully connected layer\n",
    "                    layer_weights = layer_weights.mean(axis=1).reshape(expected_shape)\n",
    "                elif len(layer_weights.shape) == 3:  # Convolutional layer\n",
    "                    layer_weights = layer_weights.mean(axis=(0, 1)).reshape(expected_shape)\n",
    "            adjusted_weights.append(layer_weights)\n",
    "\n",
    "        # Ensure the number of adjusted weights matches the number of layers\n",
    "        while len(adjusted_weights) < len(model.layers):\n",
    "            adjusted_weights.append([])\n",
    "\n",
    "        model.set_weights(adjusted_weights)\n",
    "    \n",
    "    # Fit the model with all the training data\n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=10, verbose=0)\n",
    "    \n",
    "    # Evaluate the model on the test data\n",
    "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f'Test loss: {loss:.3f}, Test accuracy: {accuracy:.3f}')\n",
    "    print(\"*********************** The value of Accuracy =\", accuracy, \"  ********************************\")\n",
    "    ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1888f-72e0-4eae-8e4c-236e77831dd0",
   "metadata": {},
   "source": [
    "### Execute FL on DL (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "07aafb73-354f-473b-b658-71f5f8e0ad15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_deep_model pid=1299)\u001b[0m 2023-05-29 14:38:46.071098: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_deep_model pid=1299)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "2023-05-29 15:00:35,405\tINFO worker.py:1625 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_220 (Dense)           (None, 64)                2624      \n",
      "                                                                 \n",
      " dense_221 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_222 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dense_223 (Dense)           (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,266\n",
      "Trainable params: 5,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1698)\u001b[0m 2023-05-29 15:00:37.351100: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=1698)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(train_deep_model pid=1698)\u001b[0m 2023-05-29 15:00:46.702213: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_deep_model pid=1698)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1  Average Accuracy: 0.9467243790626526  Total time: 493.97032713890076 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdulhameed/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:164: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asanyarray(a)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (64,) (32,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[173], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfl_dnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[172], line 36\u001b[0m, in \u001b[0;36mfl_dnn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m global_weights \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_weights()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Combine the weights from each batch and update the model\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m combined_weights \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mmean(w, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mglobal_weights)]\n\u001b[1;32m     37\u001b[0m adjusted_weights \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer_weights \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(combined_weights):\n",
      "Cell \u001b[0;32mIn[172], line 36\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m global_weights \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_weights()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Combine the weights from each batch and update the model\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m combined_weights \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mglobal_weights)]\n\u001b[1;32m     37\u001b[0m adjusted_weights \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer_weights \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(combined_weights):\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3429\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3430\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3433\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:180\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    177\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    178\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    182\u001b[0m     ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mtrue_divide(\n\u001b[1;32m    183\u001b[0m             ret, rcount, out\u001b[38;5;241m=\u001b[39mret, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (64,) (32,) "
     ]
    }
   ],
   "source": [
    "fl_dnn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
